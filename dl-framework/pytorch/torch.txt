import torch
import numpy as np

#测试GPu

flag = torch.cuda.is_available()
print(flag)

ngpu= 1
# Decide which device we want to run on
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")
print(device)
print(torch.cuda.get_device_name(0))
print(torch.rand(3,3).cuda()) 

# 模型加载

# 1.torch.save：将序列化的对象保存到disk。这个函数使用Python的pickle实用程序进行序列化。使用这个函数可以保存各种对象的模型、张量和字典。
# 2.torch.load：使用pickle unpickle工具将pickle的对象文件反序列化为内存。
# 3.torch.nn.Module.load_state_dict:使用反序列化状态字典加载model’s参数字典。

model.load_state_dict(torch.load(model_path))

# 模型部分基本格式

# class torch.nn.Module 是所有网络的基类。所有模型也应该继承这个类。
# Modules也可以包含其它Modules,允许使用树结构嵌入他们。你可以将子模块赋值给模型属性。

import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)     
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
       x = F.relu(self.conv1(x))
       y = F.relu(self.conv2(x))
       return y

# 将tensor指定index排序

torch.tensor([2,3,1])[torch.tensor([2,0,1])]

# CPU张量和GPU张量是否可以计算

device = torch.device('cuda:0')
a = torch.tensor([1,2,3])
print(a)
b = torch.tensor([1,2,3]).to(device)
print(b)

# 会报错
# print(a+b)







a = torch.nn.parameter.Parameter(torch.tensor([1,2]).float())
a

torch.Tensor.normal_(1, 0.4)

torch.Tensor([2,2,2]).normal_(1, 0.51)

a.detach()

a.detach().normal_(1,0.4)

a



a = torch.tensor([1,3]).float()
a.requires_grad = True
a






